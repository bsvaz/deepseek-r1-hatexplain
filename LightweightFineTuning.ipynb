{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f35354cd",
      "metadata": {
        "id": "f35354cd"
      },
      "source": [
        "# Lightweight Fine-Tuning Project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "560fb3ff",
      "metadata": {
        "id": "560fb3ff"
      },
      "source": [
        "TODO: In this cell, describe your choices for each of the following\n",
        "\n",
        "* PEFT technique: Soft Prompt Tuning para reduzir tempo de infer√™ncia em CPU (criar space no Hugging Face)\n",
        "* Model: unsloth/DeepSeek-R1-Distill-Qwen-1.5B-unsloth-bnb-4bit\n",
        "* Evaluation approach:\n",
        "* Fine-tuning dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de8d76bb",
      "metadata": {
        "id": "de8d76bb"
      },
      "source": [
        "## Loading and Evaluating a Foundation Model\n",
        "\n",
        "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c266dc5",
      "metadata": {
        "id": "6c266dc5"
      },
      "source": [
        "### Load Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f551c63a",
      "metadata": {
        "id": "f551c63a",
        "outputId": "776751de-b0d4-40d3-a24c-2dab7a68ee36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'label', 'target'],\n",
            "    num_rows: 1924\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "test_dataset = load_dataset(\"bsvaz/hatexplain-processed\", split='test', num_proc=8)\n",
        "print(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5483abde",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'prompt_inference_template': 'Classify the text below as Hate Speech, Offensive Language, or Normal, use the examples below to help you.\\n\\n- Labeled examples:\\n    - Offensive: <user> jokes on you because i wouldnt respect any professor who tried to teach me queer theory if they didnt look like a slut\\n    - Hate Speech: the nigger is hoping the cops beat him up and arrest him so he can wail and cry on camera and get a huge ghetto lottery payout üêí\\n    - Normal: stand up and be counted feel free to message me with any questions the ikk kk is currently taking applications we are looking for honest christian men and women who are ready to make a change ik org\\n    - Offensive: yep i am all for more black conservatives being spawned but that not our job low hanging fruit is a bazillian retarded whites\\n    - Normal: <user> <user> <user> yes because threatening a girl with rape is a serious crime sharing her info on social media encouraging others to rape her is a serious crime too\\n    - Hate Speech: question do greeks know how to tie nooses because i have yet to hear anything about niggers or sand niggers rapefugees getting lynched üòÇ\\n    - Normal: niggaz are drinking black label and corona pre game lol\\n    - Offensive: i realized women just retarded they will never look at shit the way you do\\n    - Hate Speech: lack of direction infighting we should shoot the niggers then the jews then moslems no we should shoot the jews then niggers than moslems no we should shoot the jews then wetbacks than moslems then nigs no we should shoot moslems then jews then nigs then wetbacks then moslem\\n    \\n- Notes:\\n    - Classify the text based on the *speaker\\'s* overall intent and the message conveyed by the *entire text*, not just isolated words.\\n    - \"<user>\" is a placeholder for the real username.\\n    - Your answer must have only the classification, which is one of these: Hate Speech; Offensive Language; Normal.\\n    \\n- Text: \"{}\"'}\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "# Load the YAML file containing the prompt template\n",
        "with open('prompts.yaml', 'r') as stream:\n",
        "    prompt_templates = yaml.safe_load(stream)\n",
        "\n",
        "print(prompt_templates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a1637e4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Convert your data to a HuggingFace dataset\n",
        "formatted_prompts = [prompt_templates['prompt_inference_template'].format(text) for text in test_dataset['text']]\n",
        "\n",
        "test_dataset = Dataset.from_dict({\n",
        "    'text': test_dataset['text'],\n",
        "    'prompt': formatted_prompts,\n",
        "    'label': test_dataset['label'],\n",
        "    'messages': [[{'role': 'user', 'content': formatted_prompt}] for formatted_prompt in formatted_prompts]\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a674643d",
      "metadata": {
        "id": "a674643d"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8b9d3086",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c75c3b35",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using GPU\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "from utils import generation_parameters\n",
        "import torch\n",
        "\n",
        "# Check GPU availability\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "if device == 0:\n",
        "    print(\"Using GPU\")\n",
        "else:  \n",
        "    print(\"Using CPU\")\n",
        "\n",
        "pipe = pipeline('text-generation', model=model_name, device=device, **generation_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "67ee4904",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [text, label, prediction]\n",
              "Index: []"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "test_results = pd.DataFrame(columns=['text', 'label', 'prediction'])\n",
        "test_results.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "87f00349",
      "metadata": {},
      "outputs": [],
      "source": [
        "counter_idx = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b3fa9231",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93644469b2364336adbdf05429312705",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/61 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1/61\n",
            "Processed batch 2/61\n",
            "Processed batch 3/61\n",
            "Processed batch 4/61\n",
            "Processed batch 5/61\n",
            "Processed batch 6/61\n",
            "Processed batch 7/61\n",
            "Processed batch 8/61\n",
            "Processed batch 9/61\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 10/61\n",
            "Processed batch 11/61\n",
            "Processed batch 12/61\n",
            "Processed batch 13/61\n",
            "Processed batch 14/61\n",
            "Processed batch 15/61\n",
            "Processed batch 16/61\n",
            "Processed batch 17/61\n",
            "Processed batch 18/61\n",
            "Processed batch 19/61\n",
            "Processed batch 20/61\n",
            "Processed batch 21/61\n",
            "Processed batch 22/61\n",
            "Processed batch 23/61\n",
            "Processed batch 24/61\n",
            "Processed batch 25/61\n",
            "Processed batch 26/61\n",
            "Processed batch 27/61\n",
            "Processed batch 28/61\n",
            "Processed batch 29/61\n",
            "Processed batch 30/61\n",
            "Processed batch 31/61\n",
            "Processed batch 32/61\n",
            "Processed batch 33/61\n",
            "Processed batch 34/61\n",
            "Processed batch 35/61\n",
            "Processed batch 36/61\n",
            "Processed batch 37/61\n",
            "Processed batch 38/61\n",
            "Processed batch 39/61\n",
            "Processed batch 40/61\n",
            "Processed batch 41/61\n",
            "Processed batch 42/61\n",
            "Processed batch 43/61\n",
            "Processed batch 44/61\n",
            "Processed batch 45/61\n",
            "Processed batch 46/61\n",
            "Processed batch 47/61\n",
            "Processed batch 48/61\n",
            "Processed batch 49/61\n",
            "Processed batch 50/61\n",
            "Processed batch 51/61\n",
            "Processed batch 52/61\n",
            "Processed batch 53/61\n",
            "Processed batch 54/61\n",
            "Processed batch 55/61\n",
            "Processed batch 56/61\n",
            "Processed batch 57/61\n",
            "Processed batch 58/61\n",
            "Processed batch 59/61\n",
            "Processed batch 60/61\n",
            "Processed batch 61/61\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "from transformers.pipelines.pt_utils import KeyDataset\n",
        "import time\n",
        "import gc\n",
        "\n",
        "batch_size = 32\n",
        "start_time = time.time()\n",
        "data_size = test_dataset.num_rows\n",
        "\n",
        "for i in tqdm(range(counter_idx, len(test_dataset), batch_size)):\n",
        "    batch = test_dataset['messages'][i:i + batch_size]\n",
        "    outputs = pipe(batch, batch_size=batch_size)\n",
        "    \n",
        "    # Extract the texts and labels from the batch\n",
        "    batch_texts = test_dataset['text'][i:i + batch_size]\n",
        "    batch_labels = test_dataset['label'][i:i + batch_size]\n",
        "\n",
        "    # Process each output and add to test_results\n",
        "    for j in range(len(outputs)):\n",
        "        if i + j < data_size:  # Ensure we don't go out of bounds\n",
        "            response = outputs[j][0]['generated_text']\n",
        "            \n",
        "            # Add to test_results DataFrame\n",
        "            test_results.loc[len(test_results)] = {\n",
        "                'text': batch_texts[j],\n",
        "                'label': batch_labels[j],\n",
        "                'prediction': response\n",
        "            }\n",
        "            # Save after each batch to avoid data loss\n",
        "            test_results.to_csv('test_results.csv', index=True)\n",
        "    \n",
        "    counter_idx += batch_size\n",
        "    torch.cuda.empty_cache()  # Clear GPU memory\n",
        "    gc.collect()\n",
        "\n",
        "    # Log progress after each batch\n",
        "    print(f\"Processed batch {i // batch_size + 1}/{(data_size + batch_size - 1) // batch_size}\")\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f63f81d",
      "metadata": {
        "id": "7f63f81d"
      },
      "source": [
        "### Evaluate Inference Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "24b847fc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1924 entries, 0 to 1923\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   text        1924 non-null   object\n",
            " 1   label       1924 non-null   int64 \n",
            " 2   prediction  1924 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 45.2+ KB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "test_results_df = pd.read_csv('test_results.csv')\n",
        "test_results_df.head()\n",
        "test_results_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a63a1971",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    [{'content': 'Classify the text below as Hate ...\n",
            "1    [{'content': 'Classify the text below as Hate ...\n",
            "2    [{'content': 'Classify the text below as Hate ...\n",
            "3    [{'content': 'Classify the text below as Hate ...\n",
            "4    [{'content': 'Classify the text below as Hate ...\n",
            "Name: prediction, dtype: object\n",
            "<class 'list'>\n"
          ]
        }
      ],
      "source": [
        "import ast\n",
        "\n",
        "# Parse the 'prediction' column to convert strings to lists\n",
        "test_results_df['prediction'] = test_results_df['prediction'].apply(ast.literal_eval)\n",
        "\n",
        "# Verify the change\n",
        "print(test_results_df['prediction'].head())\n",
        "print(type(test_results_df['prediction'][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "07f975ca",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'role': 'assistant',\n",
              " 'content': 'Alright, so I\\'m trying to classify this text into hate speech, offensive language, or normal. Let me read through it carefully.\\n\\nThe text is: \"<user> men can not be raped can not be abuse that why they call it violence against women and children because men are always the perpetrators women come first even before children\"\\n\\nHmm, okay. So the speaker is talking about men being unable to be raped or abused, and they\\'re pointing out that violence is against women and children. They say that men are always the perpetrators and that women come first. \\n\\nI remember the examples given. Offensive language is when someone makes comments that target someone else\\'s appearance or background, like looking like a slut. That doesn\\'t seem to fit here. \\n\\nHate speech is when someone attacks another group or person with harsh words, often with a sense of judgment or superiority. The speaker here is not attacking anyone negatively; they\\'re pointing out a stereotype and explaining that women come first. \\n\\nNormal language is for everyday conversations or statements that don\\'t fall into the other categories. This seems to be a straightforward statement about societal norms and stereotypes, so it\\'s probably classified as Normal.\\n</think>\\n\\nNormal'}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_results_df['prediction'][0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e8389ad0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add \"<think>\" at the beginning of 'content' in the second item of each prediction list\n",
        "for i in range(len(test_results_df)):\n",
        "    if len(test_results_df['prediction'][i]) > 1:  # Make sure there's a second item\n",
        "        if 'content' in test_results_df['prediction'][i][1]:\n",
        "            test_results_df['prediction'][i][1]['content'] = \"<think>\" + test_results_df['prediction'][i][1]['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "17ce5d0f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import extract_components\n",
        "extracted = extract_components(test_results_df['prediction'][0][1]['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f87afa55",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_response</th>\n",
              "      <th>thinking</th>\n",
              "      <th>predicted_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;think&gt;Alright, so I'm trying to classify this...</td>\n",
              "      <td>Alright, so I'm trying to classify this text i...</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;think&gt;Okay, so I'm trying to figure out wheth...</td>\n",
              "      <td>Okay, so I'm trying to figure out whether the ...</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;think&gt;Okay, so I have this text: \"&lt;user&gt; &lt;use...</td>\n",
              "      <td>Okay, so I have this text: \"&lt;user&gt; &lt;user&gt; why ...</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;think&gt;Okay, so I'm looking at this text: \"&lt;us...</td>\n",
              "      <td>Okay, so I'm looking at this text: \"&lt;user&gt; &lt;us...</td>\n",
              "      <td>Offensive Language</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;think&gt;Alright, let's try to figure out what t...</td>\n",
              "      <td>Alright, let's try to figure out what the user...</td>\n",
              "      <td>Offensive Language</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       full_response  \\\n",
              "0  <think>Alright, so I'm trying to classify this...   \n",
              "1  <think>Okay, so I'm trying to figure out wheth...   \n",
              "2  <think>Okay, so I have this text: \"<user> <use...   \n",
              "3  <think>Okay, so I'm looking at this text: \"<us...   \n",
              "4  <think>Alright, let's try to figure out what t...   \n",
              "\n",
              "                                            thinking     predicted_label  \n",
              "0  Alright, so I'm trying to classify this text i...              Normal  \n",
              "1  Okay, so I'm trying to figure out whether the ...              Normal  \n",
              "2  Okay, so I have this text: \"<user> <user> why ...              Normal  \n",
              "3  Okay, so I'm looking at this text: \"<user> <us...  Offensive Language  \n",
              "4  Alright, let's try to figure out what the user...  Offensive Language  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Apply extract_components to each row in test_results_df\n",
        "extracted_data = []\n",
        "for i in range(len(test_results_df)):\n",
        "\tif len(test_results_df['prediction'][i]) > 1 and 'content' in test_results_df['prediction'][i][1]:\n",
        "\t\textracted_data.append(extract_components(test_results_df['prediction'][i][1]['content']))\n",
        "\telse:\n",
        "\t\t# Handle cases where the prediction doesn't have enough elements or right structure\n",
        "\t\textracted_data.append({'full_response': None, 'thinking': None, 'predicted_label': None})\n",
        "\n",
        "# Create DataFrame from the extracted data\n",
        "processed_results = pd.DataFrame(extracted_data)\n",
        "processed_results.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "77b5d97d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 1, 2, 0, 2]\n",
            "['Normal', 'Normal', 'Normal', 'Offensive Language', 'Offensive Language']\n"
          ]
        }
      ],
      "source": [
        "from utils import label_map\n",
        "\n",
        "references = list(pd.read_csv('test_data.csv')['label'])\n",
        "print(references[:5])\n",
        "\n",
        "predictions = processed_results['predicted_label'].tolist()\n",
        "print(predictions[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "22873698",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique prediction classes: {'Hate Speech', None, 'Normal', 'Offensive Language'}\n"
          ]
        }
      ],
      "source": [
        "unique_predictions = set(predictions)\n",
        "print(\"Unique prediction classes:\", unique_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "83d99057",
      "metadata": {
        "id": "83d99057",
        "outputId": "1ec7001c-5e3c-48ce-c504-809196ce62ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computed metrics on 1921 out of 1924 examples\n",
            "Accuracy: {'accuracy': 0.3909422175950026}\n",
            "Weighted F1 Score: {'f1': 0.32953267428470956}\n"
          ]
        }
      ],
      "source": [
        "import evaluate\n",
        "\n",
        "# Load evaluation metrics\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "# Create reverse label mapping without None\n",
        "reverse_label_map = {v: k for k, v in label_map.items()}\n",
        "reverse_label_map_pred = {'Hate Speech': 0, 'Normal': 1, 'Offensive Language': 2}\n",
        "\n",
        "# Filter out None values from predictions\n",
        "valid_indices = [i for i, pred in enumerate(predictions) if pred is not None]\n",
        "valid_predictions = [predictions[i] for i in valid_indices]\n",
        "valid_references = [references[i] for i in valid_indices]\n",
        "\n",
        "# Convert valid predictions to integers\n",
        "valid_predictions_int = [reverse_label_map_pred[pred] for pred in valid_predictions]\n",
        "\n",
        "# Compute metrics only on valid data\n",
        "acc_result = accuracy_metric.compute(predictions=valid_predictions_int, references=valid_references)\n",
        "f1_result = f1_metric.compute(predictions=valid_predictions_int, references=valid_references, average=\"weighted\")\n",
        "\n",
        "print(f\"Computed metrics on {len(valid_predictions)} out of {len(predictions)} examples\")\n",
        "print(\"Accuracy:\", acc_result)\n",
        "print(\"Weighted F1 Score:\", f1_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2b5564c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "309dfcbf42a5441897f05f5a8057043b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "ValueError",
          "evalue": "Number of processes must be at least 1",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m----> 3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcsv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_prompts.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m dataset\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/datasets/load.py:2151\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance\u001b[38;5;241m.\u001b[39mas_streaming_dataset(split\u001b[38;5;241m=\u001b[39msplit)\n\u001b[1;32m   2150\u001b[0m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 2151\u001b[0m \u001b[43mbuilder_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2157\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2159\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   2160\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2161\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[1;32m   2162\u001b[0m )\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/datasets/builder.py:924\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    923\u001b[0m     prepare_split_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_proc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_proc\n\u001b[0;32m--> 924\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(split\u001b[38;5;241m.\u001b[39mnum_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mvalues())\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/datasets/builder.py:1000\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    996\u001b[0m split_dict\u001b[38;5;241m.\u001b[39madd(split_generator\u001b[38;5;241m.\u001b[39msplit_info)\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;66;03m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[0;32m-> 1000\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m   1003\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find data file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1004\u001b[0m         \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_download_instructions \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1005\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOriginal error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1006\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m   1007\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/datasets/builder.py:1768\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split\u001b[0;34m(self, split_generator, file_format, num_proc, max_shard_size)\u001b[0m\n\u001b[1;32m   1765\u001b[0m shards_per_job \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m num_jobs\n\u001b[1;32m   1766\u001b[0m shard_lengths_per_job \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m num_jobs\n\u001b[0;32m-> 1768\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[1;32m   1769\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m pbar:\n\u001b[1;32m   1770\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m job_id, done, content \u001b[38;5;129;01min\u001b[39;00m iflatmap_unordered(\n\u001b[1;32m   1771\u001b[0m             pool, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_split_single, kwargs_iterable\u001b[38;5;241m=\u001b[39mkwargs_per_job\n\u001b[1;32m   1772\u001b[0m         ):\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/multiprocess/context.py:119\u001b[0m, in \u001b[0;36mBaseContext.Pool\u001b[0;34m(self, processes, initializer, initargs, maxtasksperchild)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Returns a process pool object'''\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpool\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pool\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxtasksperchild\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/multiprocess/pool.py:205\u001b[0m, in \u001b[0;36mPool.__init__\u001b[0;34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001b[0m\n\u001b[1;32m    203\u001b[0m     processes \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mcpu_count() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m processes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of processes must be at least 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxtasksperchild \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maxtasksperchild, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m maxtasksperchild \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "\u001b[0;31mValueError\u001b[0m: Number of processes must be at least 1"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset('csv', 'test_prompts.csv')\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c501694a",
      "metadata": {
        "id": "c501694a"
      },
      "source": [
        "## Preparing the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "eb3a2cd7",
      "metadata": {
        "id": "eb3a2cd7",
        "outputId": "1f489894-a93f-48b4-abe6-0181171e0e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "Creating prompts CSV file...\n",
            "Loaded 43 previously processed results.\n",
            "Starting phase for label: Offensive Language\n",
            "Already processed 20 rows for label: Offensive Language\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Offensive Language: correct_count = 32\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Offensive Language: correct_count = 59\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Offensive Language: correct_count = 90\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Offensive Language: correct_count = 118\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Offensive Language: correct_count = 137\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Offensive Language: correct_count = 161\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Offensive Language: correct_count = 184\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Offensive Language: correct_count = 213\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Offensive Language: correct_count = 238\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Offensive Language: correct_count = 265\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Offensive Language: correct_count = 293\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Offensive Language: correct_count = 317\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Offensive Language: correct_count = 345\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Offensive Language: correct_count = 367\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Offensive Language: correct_count = 390\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Offensive Language: correct_count = 410\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Offensive Language: correct_count = 437\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Offensive Language: correct_count = 460\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Offensive Language: correct_count = 491\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Offensive Language: correct_count = 500\n",
            "Completed phase for label: Offensive Language with 500 correct responses.\n",
            "Starting phase for label: Normal\n",
            "Already processed 23 rows for label: Normal\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 34\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 63\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 85\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 104\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 122\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 147\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 171\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 194\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 217\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 235\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 263\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 280\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 304\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 327\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 350\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 369\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 390\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 410\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 434\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 453\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 474\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 497\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Normal: correct_count = 500\n",
            "Completed phase for label: Normal with 500 correct responses.\n",
            "Starting phase for label: Hate Speech\n",
            "Already processed 0 rows for label: Hate Speech\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Hate Speech: correct_count = 45\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Hate Speech: correct_count = 92\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Hate Speech: correct_count = 139\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Hate Speech: correct_count = 187\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Hate Speech: correct_count = 235\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Hate Speech: correct_count = 279\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Hate Speech: correct_count = 324\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Hate Speech: correct_count = 368\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Hate Speech: correct_count = 418\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Hate Speech: correct_count = 460\n",
            "Sending 50 asynchronous requests...\n",
            "Phase Hate Speech: correct_count = 500\n",
            "Completed phase for label: Hate Speech with 500 correct responses.\n",
            "Processing completed. Results saved to train_reasoning_data.csv\n"
          ]
        }
      ],
      "source": [
        "!python generate_train_data.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f477103d",
      "metadata": {
        "id": "f477103d",
        "outputId": "bef3e22f-581f-441c-e048-effebd51685c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>thinking</th>\n",
              "      <th>full_responses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>if english is not imposition then hindi is als...</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Okay, let me try to work through this classifi...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, let me try to work through this...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>he said bro even your texts sound redneck what...</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Okay, let's see. I need to classify the text \"...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, let's see. I need to classify t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i am sure you are totally the alpha faggot at ...</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Okay, let me try to figure out how to classify...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, let me try to figure out how to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;user&gt; aint he bisexual an lgbt king of gays e...</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Okay, let's tackle this classification step by...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, let's tackle this classificatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;user&gt; agree with ananya baby every hindu musl...</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Okay, let's try to classify this text. The inp...</td>\n",
              "      <td>&lt;think&gt;\\nOkay, let's try to classify this text...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text     predicted_label  \\\n",
              "0  if english is not imposition then hindi is als...  Offensive Language   \n",
              "1  he said bro even your texts sound redneck what...  Offensive Language   \n",
              "2  i am sure you are totally the alpha faggot at ...  Offensive Language   \n",
              "3  <user> aint he bisexual an lgbt king of gays e...  Offensive Language   \n",
              "4  <user> agree with ananya baby every hindu musl...  Offensive Language   \n",
              "\n",
              "                                            thinking  \\\n",
              "0  Okay, let me try to work through this classifi...   \n",
              "1  Okay, let's see. I need to classify the text \"...   \n",
              "2  Okay, let me try to figure out how to classify...   \n",
              "3  Okay, let's tackle this classification step by...   \n",
              "4  Okay, let's try to classify this text. The inp...   \n",
              "\n",
              "                                      full_responses  \n",
              "0  <think>\\nOkay, let me try to work through this...  \n",
              "1  <think>\\nOkay, let's see. I need to classify t...  \n",
              "2  <think>\\nOkay, let me try to figure out how to...  \n",
              "3  <think>\\nOkay, let's tackle this classificatio...  \n",
              "4  <think>\\nOkay, let's try to classify this text...  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "reasoning_df = pd.read_csv('train_reasoning_data.csv')\n",
        "reasoning_df.rename(columns={'label': 'predicted_label'}, inplace=True)\n",
        "reasoning_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fc80ccb1",
      "metadata": {
        "id": "fc80ccb1",
        "outputId": "6a327ab3-08ab-4d5b-f8b1-e0209349db38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1500 entries, 0 to 1499\n",
            "Data columns (total 4 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   text             1500 non-null   object\n",
            " 1   predicted_label  1500 non-null   object\n",
            " 2   thinking         1500 non-null   object\n",
            " 3   full_responses   1500 non-null   object\n",
            "dtypes: object(4)\n",
            "memory usage: 47.0+ KB\n"
          ]
        }
      ],
      "source": [
        "reasoning_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4a28f9e2",
      "metadata": {
        "id": "4a28f9e2",
        "outputId": "424babbe-2699-4272-a6db-732f73bbc16a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u really think i would not have been raped by ...</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>['Hindu', 'Other', 'Islam']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the uk has threatened to return radioactive wa...</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>['Indian', 'Refugee', 'Minority', 'Islam']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>if english is not imposition then hindi is als...</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>['Hindu', 'Other']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>no liberal congratulated hindu refugees post c...</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>['Hindu']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>he said bro even your texts sound redneck what...</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>['Caucasian', 'Economic']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text               label  \\\n",
              "0  u really think i would not have been raped by ...  Offensive Language   \n",
              "1  the uk has threatened to return radioactive wa...  Offensive Language   \n",
              "2  if english is not imposition then hindi is als...  Offensive Language   \n",
              "3  no liberal congratulated hindu refugees post c...  Offensive Language   \n",
              "4  he said bro even your texts sound redneck what...  Offensive Language   \n",
              "\n",
              "                                       target  \n",
              "0                 ['Hindu', 'Other', 'Islam']  \n",
              "1  ['Indian', 'Refugee', 'Minority', 'Islam']  \n",
              "2                          ['Hindu', 'Other']  \n",
              "3                                   ['Hindu']  \n",
              "4                   ['Caucasian', 'Economic']  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_map = {0: 'Hate Speech', 1: 'Normal', 2: 'Offensive Language'}\n",
        "\n",
        "train_df = pd.read_csv('train_data.csv')\n",
        "train_df['label'] = train_df['label'].map(label_map)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "33eccf37",
      "metadata": {
        "id": "33eccf37",
        "outputId": "87ccb068-ff39-4bab-dcba-9a18ba8b1d3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merged DataFrame Info:\n",
            "--------------------\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1517 entries, 0 to 1516\n",
            "Data columns (total 4 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   text             1517 non-null   object\n",
            " 1   predicted_label  1517 non-null   object\n",
            " 2   label            1517 non-null   object\n",
            " 3   thinking         1517 non-null   object\n",
            "dtypes: object(4)\n",
            "memory usage: 47.5+ KB\n",
            "\n",
            "First few rows:\n",
            "--------------------\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>label</th>\n",
              "      <th>thinking</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>if english is not imposition then hindi is als...</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Okay, let me try to work through this classifi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>he said bro even your texts sound redneck what...</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Okay, let's see. I need to classify the text \"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i am sure you are totally the alpha faggot at ...</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Okay, let me try to figure out how to classify...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;user&gt; aint he bisexual an lgbt king of gays e...</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Okay, let's tackle this classification step by...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;user&gt; agree with ananya baby every hindu musl...</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Okay, let's try to classify this text. The inp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text     predicted_label  \\\n",
              "0  if english is not imposition then hindi is als...  Offensive Language   \n",
              "1  he said bro even your texts sound redneck what...  Offensive Language   \n",
              "2  i am sure you are totally the alpha faggot at ...  Offensive Language   \n",
              "3  <user> aint he bisexual an lgbt king of gays e...  Offensive Language   \n",
              "4  <user> agree with ananya baby every hindu musl...  Offensive Language   \n",
              "\n",
              "                label                                           thinking  \n",
              "0  Offensive Language  Okay, let me try to work through this classifi...  \n",
              "1  Offensive Language  Okay, let's see. I need to classify the text \"...  \n",
              "2  Offensive Language  Okay, let me try to figure out how to classify...  \n",
              "3  Offensive Language  Okay, let's tackle this classification step by...  \n",
              "4  Offensive Language  Okay, let's try to classify this text. The inp...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Merge the dataframes using inner join on 'text' column\n",
        "merged_df = pd.merge(reasoning_df, train_df, on='text', how='left')[['text', 'predicted_label', 'label', 'thinking']]\n",
        "\n",
        "# Display info about the merged dataframe\n",
        "print(\"Merged DataFrame Info:\")\n",
        "print(\"-\" * 20)\n",
        "merged_df.info()\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(\"-\" * 20)\n",
        "merged_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7c10e561",
      "metadata": {},
      "outputs": [],
      "source": [
        "merged_df.drop_duplicates(subset=['text'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "88df258a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1499 entries, 0 to 1516\n",
            "Data columns (total 4 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   text             1499 non-null   object\n",
            " 1   predicted_label  1499 non-null   object\n",
            " 2   label            1499 non-null   object\n",
            " 3   thinking         1499 non-null   object\n",
            "dtypes: object(4)\n",
            "memory usage: 58.6+ KB\n"
          ]
        }
      ],
      "source": [
        "merged_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3e2895b6",
      "metadata": {
        "id": "3e2895b6",
        "outputId": "77c402b4-5ef0-44a3-a270-942e8a3cf6c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 99.93%\n"
          ]
        }
      ],
      "source": [
        "from utils import calculate_response_accuracy\n",
        "\n",
        "# Calculate response accuracy\n",
        "calculate_response_accuracy(merged_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c44caab5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows where 'label' and 'predicted_label' are different: 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>label</th>\n",
              "      <th>thinking</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>&lt;user&gt; i hate you</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Okay, let's try to classify the text \"&lt;user&gt; i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  text     predicted_label   label  \\\n",
              "429  <user> i hate you  Offensive Language  Normal   \n",
              "\n",
              "                                              thinking  \n",
              "429  Okay, let's try to classify the text \"<user> i...  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find rows where 'label' and 'predicted_label' are different\n",
        "different_labels_df = merged_df[merged_df['label'] != merged_df['predicted_label']]\n",
        "\n",
        "# Print the number of rows where labels are different\n",
        "print(f\"Number of rows where 'label' and 'predicted_label' are different: {len(different_labels_df)}\")\n",
        "\n",
        "# Display the rows where labels are different\n",
        "different_labels_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6144b029",
      "metadata": {},
      "outputs": [],
      "source": [
        "merged_df = merged_df.drop(429)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "97152a9a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "# Calculate response accuracy\n",
        "calculate_response_accuracy(merged_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "82bb326c",
      "metadata": {},
      "outputs": [],
      "source": [
        "merged_df.to_csv('train_reasoning_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2f1fb446",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1498 entries, 0 to 1497\n",
            "Data columns (total 4 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   text             1498 non-null   object\n",
            " 1   predicted_label  1498 non-null   object\n",
            " 2   label            1498 non-null   object\n",
            " 3   thinking         1498 non-null   object\n",
            "dtypes: object(4)\n",
            "memory usage: 46.9+ KB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('train_reasoning_data.csv')\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b3b6a8df",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>label</th>\n",
              "      <th>thinking</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>if english is not imposition then hindi is als...</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Okay, let me try to work through this classifi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>he said bro even your texts sound redneck what...</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Okay, let's see. I need to classify the text \"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i am sure you are totally the alpha faggot at ...</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Okay, let me try to figure out how to classify...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;user&gt; aint he bisexual an lgbt king of gays e...</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Okay, let's tackle this classification step by...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;user&gt; agree with ananya baby every hindu musl...</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>Okay, let's try to classify this text. The inp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text     predicted_label  \\\n",
              "0  if english is not imposition then hindi is als...  Offensive Language   \n",
              "1  he said bro even your texts sound redneck what...  Offensive Language   \n",
              "2  i am sure you are totally the alpha faggot at ...  Offensive Language   \n",
              "3  <user> aint he bisexual an lgbt king of gays e...  Offensive Language   \n",
              "4  <user> agree with ananya baby every hindu musl...  Offensive Language   \n",
              "\n",
              "                label                                           thinking  \n",
              "0  Offensive Language  Okay, let me try to work through this classifi...  \n",
              "1  Offensive Language  Okay, let's see. I need to classify the text \"...  \n",
              "2  Offensive Language  Okay, let me try to figure out how to classify...  \n",
              "3  Offensive Language  Okay, let's tackle this classification step by...  \n",
              "4  Offensive Language  Okay, let's try to classify this text. The inp...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f9484ae9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classify the text below as Hate Speech, Offensive Language, or Normal, use the examples below to help you.\n",
            "    \n",
            "- Labeled examples:\n",
            "    - Offensive Language: <user> jokes on you because i wouldnt respect any professor who tried to teach me queer theory if they didnt look like a slut\n",
            "    - Hate Speech: the nigger is hoping the cops beat him up and arrest him so he can wail and cry on camera and get a huge ghetto lottery payout üêí\n",
            "    - Normal: stand up and be counted feel free to message me with any questions the ikk kk is currently taking applications we are looking for honest christian men and women who are ready to make a change ik org\n",
            "    - Offensive Language: yep i am all for more black conservatives being spawned but that not our job low hanging fruit is a bazillian retarded whites\n",
            "    - Normal: <user> <user> <user> yes because threatening a girl with rape is a serious crime sharing her info on social media encouraging others to rape her is a serious crime too\n",
            "    - Hate Speech: question do greeks know how to tie nooses because i have yet to hear anything about niggers or sand niggers rapefugees getting lynched üòÇ\n",
            "    - Normal: niggaz are drinking black label and corona pre game lol\n",
            "    - Offensive Language: i realized women just retarded they will never look at shit the way you do\n",
            "    - Hate Speech: lack of direction infighting we should shoot the niggers then the jews then moslems no we should shoot the jews then niggers than moslems no we should shoot the jews then wetbacks than moslems then nigs no we should shoot moslems then jews then nigs then wetbacks then moslem\n",
            "\n",
            "- Notes:\n",
            "    - Classify the text based on the *speaker's* overall intent and the message conveyed by the *entire text*, not just isolated words.\n",
            "    - \"<user>\" is a placeholder for the real username.\n",
            "    - Your answer must have only the classification, which is one of these: Hate Speech; Offensive Language; Normal.\n",
            "    \n",
            "- Text: \"{}\"\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "\n",
        "# Load the YAML file containing the prompt template\n",
        "with open('prompts.yaml', 'r') as stream:\n",
        "    prompt_template = yaml.safe_load(stream)['prompt_inference_template']\n",
        "\n",
        "print(prompt_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "138a14f8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully created training_data.jsonl with 1498 examples\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Create a list to store the formatted examples\n",
        "formatted_examples = []\n",
        "\n",
        "# Process each row in the dataframe\n",
        "for _, row in df.iterrows():\n",
        "    # Format the prompt with the text\n",
        "    formatted_prompt = prompt_template.format(row['text'])\n",
        "    \n",
        "    # Format the assistant response\n",
        "    assistant_response = row['thinking'] + \"</think>\\n\\n\" + row['label']\n",
        "    \n",
        "    # Create the message object\n",
        "    message_obj = {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": formatted_prompt},\n",
        "            {\"role\": \"assistant\", \"content\": assistant_response}\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    # Add to our examples list\n",
        "    formatted_examples.append(message_obj)\n",
        "\n",
        "# Write to JSONL file\n",
        "with open('training_data.jsonl', 'w', encoding='utf-8') as f:\n",
        "    for example in formatted_examples:\n",
        "        f.write(json.dumps(example, ensure_ascii=False) + '\\n')\n",
        "\n",
        "print(f\"Successfully created training_data.jsonl with {len(formatted_examples)} examples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d0bbb3d6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4cba2ee50244c798e31568f7fd3dad4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fcd481059d344279b41bb83a20af090",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75a70e98c90245e4a46fdff07e239ca5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset successfully pushed to Hugging Face Hub!\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Assuming you have a Hugging Face token as an environment variable or will enter it when prompted\n",
        "login()\n",
        "\n",
        "# Load the dataset from the JSONL file\n",
        "dataset = load_dataset('json', data_files='training_data.jsonl')\n",
        "\n",
        "# Push the dataset to the Hugging Face Hub\n",
        "# Replace 'your-username/your-dataset-name' with your desired repository name\n",
        "dataset.push_to_hub('bsvaz/hatexplain-reasoning-dataset', private=False)\n",
        "\n",
        "print(\"Dataset successfully pushed to Hugging Face Hub!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d52a229",
      "metadata": {
        "id": "4d52a229"
      },
      "source": [
        "## Performing Parameter-Efficient Fine-Tuning\n",
        "\n",
        "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b47abf88",
      "metadata": {
        "id": "b47abf88"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "615b12c6",
      "metadata": {
        "id": "615b12c6"
      },
      "source": [
        "## Performing Inference with a PEFT Model\n",
        "\n",
        "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "863ec66e",
      "metadata": {
        "id": "863ec66e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc3a8147",
      "metadata": {
        "id": "bc3a8147"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc96905a",
      "metadata": {
        "id": "bc96905a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "866ab28c",
      "metadata": {
        "id": "866ab28c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9a32e4e",
      "metadata": {
        "id": "f9a32e4e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cloudspace",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
